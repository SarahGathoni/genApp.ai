"use strict";
/**
 * @license
 * Copyright 2023 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
Object.defineProperty(exports, "__esModule", { value: true });
exports.testGenerator = void 0;
const types_1 = require("../../types");
const util_1 = require("../../util");
const count_tokens_1 = require("../count_tokens");
const generate_content_1 = require("../generate_content");
const StreamFunctions = require("../post_fetch_processing");
const TEST_PROJECT = 'test-project';
const TEST_LOCATION = 'test-location';
const TEST_PUBLISHER_MODEL_ENDPOINT = 'test-publisher-model-endpoint';
const TEST_TOKEN = 'testtoken';
const TEST_TOKEN_PROMISE = Promise.resolve(TEST_TOKEN);
const TEST_API_ENDPOINT = 'test-api-endpoint';
const TEST_CHAT_MESSAGE_TEXT = 'How are you doing today?';
const TEST_USER_CHAT_MESSAGE = [
    { role: util_1.constants.USER_ROLE, parts: [{ text: TEST_CHAT_MESSAGE_TEXT }] },
];
const TEST_USER_CHAT_MESSAGE_WITH_GCS_FILE = [
    {
        role: util_1.constants.USER_ROLE,
        parts: [
            { text: TEST_CHAT_MESSAGE_TEXT },
            {
                file_data: {
                    file_uri: 'gs://test_bucket/test_image.jpeg',
                    mime_type: 'image/jpeg',
                },
            },
        ],
    },
];
const TEST_USER_CHAT_MESSAGE_WITH_INVALID_GCS_FILE = [
    {
        role: util_1.constants.USER_ROLE,
        parts: [
            { text: TEST_CHAT_MESSAGE_TEXT },
            { file_data: { file_uri: 'test_image.jpeg', mime_type: 'image/jpeg' } },
        ],
    },
];
const TEST_SAFETY_SETTINGS = [
    {
        category: types_1.HarmCategory.HARM_CATEGORY_HATE_SPEECH,
        threshold: types_1.HarmBlockThreshold.BLOCK_ONLY_HIGH,
    },
];
const TEST_SAFETY_RATINGS = [
    {
        category: types_1.HarmCategory.HARM_CATEGORY_HATE_SPEECH,
        probability: types_1.HarmProbability.NEGLIGIBLE,
    },
];
const TEST_GENERATION_CONFIG = {
    candidate_count: 1,
    stop_sequences: ['hello'],
};
const TEST_CANDIDATES = [
    {
        index: 1,
        content: {
            role: util_1.constants.MODEL_ROLE,
            parts: [{ text: 'Im doing great! How are you?' }],
        },
        finishReason: types_1.FinishReason.STOP,
        finishMessage: '',
        safetyRatings: TEST_SAFETY_RATINGS,
        citationMetadata: {
            citationSources: [
                {
                    startIndex: 367,
                    endIndex: 491,
                    uri: 'https://www.numerade.com/ask/question/why-does-the-uncertainty-principle-make-it-impossible-to-predict-a-trajectory-for-the-clectron-95172/',
                },
            ],
        },
    },
];
const TEST_MODEL_RESPONSE = {
    candidates: TEST_CANDIDATES,
    usage_metadata: { prompt_token_count: 0, candidates_token_count: 0 },
};
const TEST_FUNCTION_CALL_RESPONSE = {
    functionCall: {
        name: 'get_current_weather',
        args: {
            location: 'LA',
            unit: 'fahrenheit',
        },
    },
};
const TEST_CANDIDATES_WITH_FUNCTION_CALL = [
    {
        index: 1,
        content: {
            role: util_1.constants.MODEL_ROLE,
            parts: [TEST_FUNCTION_CALL_RESPONSE],
        },
        finishReason: types_1.FinishReason.STOP,
        finishMessage: '',
        safetyRatings: TEST_SAFETY_RATINGS,
    },
];
const TEST_MODEL_RESPONSE_WITH_FUNCTION_CALL = {
    candidates: TEST_CANDIDATES_WITH_FUNCTION_CALL,
};
const TEST_FUNCTION_RESPONSE_PART = [
    {
        functionResponse: {
            name: 'get_current_weather',
            response: { name: 'get_current_weather', content: { weather: 'super nice' } },
        },
    },
];
const TEST_CANDIDATES_MISSING_ROLE = [
    {
        index: 1,
        content: { parts: [{ text: 'Im doing great! How are you?' }] },
        finish_reason: 0,
        finish_message: '',
        safety_ratings: TEST_SAFETY_RATINGS,
    },
];
const TEST_ENDPOINT_BASE_PATH = 'test.googleapis.com';
const TEST_GCS_FILENAME = 'gs://test_bucket/test_image.jpeg';
const TEST_MULTIPART_MESSAGE = [
    {
        role: util_1.constants.USER_ROLE,
        parts: [
            { text: 'What is in this picture?' },
            { file_data: { file_uri: TEST_GCS_FILENAME, mime_type: 'image/jpeg' } },
        ],
    },
];
const BASE_64_IMAGE = 'iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==';
const INLINE_DATA_FILE_PART = {
    inline_data: {
        data: BASE_64_IMAGE,
        mime_type: 'image/jpeg',
    },
};
const TEST_MULTIPART_MESSAGE_BASE64 = [
    {
        role: util_1.constants.USER_ROLE,
        parts: [{ text: 'What is in this picture?' }, INLINE_DATA_FILE_PART],
    },
];
const TEST_TOOLS_WITH_FUNCTION_DECLARATION = [
    {
        function_declarations: [
            {
                name: 'get_current_weather',
                description: 'get weather in a given location',
                parameters: {
                    type: types_1.FunctionDeclarationSchemaType.OBJECT,
                    properties: {
                        location: { type: types_1.FunctionDeclarationSchemaType.STRING },
                        unit: {
                            type: types_1.FunctionDeclarationSchemaType.STRING,
                            enum: ['celsius', 'fahrenheit'],
                        },
                    },
                    required: ['location'],
                },
            },
        ],
    },
];
const fetchResponseObj = {
    status: 200,
    statusText: 'OK',
    ok: true,
    headers: { 'Content-Type': 'application/json' },
    url: 'url',
};
/**
 * Returns a generator, used to mock the generateContentStream response
 * @ignore
 */
async function* testGenerator() {
    yield {
        candidates: TEST_CANDIDATES,
    };
}
exports.testGenerator = testGenerator;
describe('countTokens', () => {
    const req = {
        contents: TEST_USER_CHAT_MESSAGE,
    };
    it('return expected response when OK', async () => {
        const expectedResponseBody = {
            totalTokens: 1,
        };
        const response = new Response(JSON.stringify(expectedResponseBody), fetchResponseObj);
        spyOn(global, 'fetch').and.resolveTo(response);
        const resp = await (0, count_tokens_1.countTokens)(TEST_LOCATION, TEST_PROJECT, TEST_PUBLISHER_MODEL_ENDPOINT, TEST_TOKEN_PROMISE, req, TEST_API_ENDPOINT);
        expect(resp).toEqual(expectedResponseBody);
    });
    it('throw GoogleGenerativeError when not OK and not 4XX', async () => {
        const fetch500Obj = {
            status: 500,
            statusText: 'Internal Server Error',
            ok: false,
        };
        const body = {
            code: 500,
            message: 'service is having downtime',
            status: 'INTERNAL_SERVER_ERROR',
        };
        const response = new Response(JSON.stringify(body), fetch500Obj);
        const expectedErrorMessage = '[VertexAI.GoogleGenerativeAIError]: got status: 500 Internal Server Error. {"code":500,"message":"service is having downtime","status":"INTERNAL_SERVER_ERROR"}';
        spyOn(global, 'fetch').and.resolveTo(response);
        await expectAsync((0, count_tokens_1.countTokens)(TEST_LOCATION, TEST_PROJECT, TEST_PUBLISHER_MODEL_ENDPOINT, TEST_TOKEN_PROMISE, req, TEST_API_ENDPOINT)).toBeRejected();
        // TODO: update jasmine version or use flush to uncomment
        // await countTokens(
        //   TEST_LOCATION,
        //   TEST_PROJECT,
        //   TEST_PUBLISHER_MODEL_ENDPOINT,
        //   TEST_TOKEN_PROMISE,
        //   req,
        //   TEST_API_ENDPOINT
        // ).catch(e => {
        //   expect(e.message).toEqual(expectedErrorMessage);
        // });
    });
    it('throw ClientError when not OK and 4XX', async () => {
        const fetch400Obj = {
            status: 400,
            statusText: 'Bad Request',
            ok: false,
        };
        const body = {
            code: 400,
            message: 'request is invalid',
            status: 'INVALID_ARGUMENT',
        };
        const response = new Response(JSON.stringify(body), fetch400Obj);
        const expectedErrorMessage = '[VertexAI.ClientError]: got status: 400 Bad Request. {"code":400,"message":"request is invalid","status":"INVALID_ARGUMENT"}';
        spyOn(global, 'fetch').and.resolveTo(response);
        await expectAsync((0, count_tokens_1.countTokens)(TEST_LOCATION, TEST_PROJECT, TEST_PUBLISHER_MODEL_ENDPOINT, TEST_TOKEN_PROMISE, req, TEST_API_ENDPOINT)).toBeRejected();
        // TODO: update jasmine version or use flush to uncomment
        // await countTokens(
        //   TEST_LOCATION,
        //   TEST_PROJECT,
        //   TEST_PUBLISHER_MODEL_ENDPOINT,
        //   TEST_TOKEN_PROMISE,
        //   req,
        //   TEST_API_ENDPOINT
        // ).catch(e => {
        //   expect(e.message).toEqual(expectedErrorMessage);
        // });
    });
});
describe('generateContent', () => {
    let expectedStreamResult;
    let fetchSpy;
    beforeEach(() => {
        expectedStreamResult = {
            response: Promise.resolve(TEST_MODEL_RESPONSE),
            stream: testGenerator(),
        };
        const fetchResult = new Response(JSON.stringify(expectedStreamResult), fetchResponseObj);
        fetchSpy = spyOn(global, 'fetch').and.resolveTo(fetchResult);
    });
    it('returns a GenerateContentResponse', async () => {
        const req = {
            contents: TEST_USER_CHAT_MESSAGE,
        };
        const expectedResult = {
            response: TEST_MODEL_RESPONSE,
        };
        spyOn(StreamFunctions, 'processNonStream').and.resolveTo(expectedResult);
        const resp = await (0, generate_content_1.generateContent)(TEST_LOCATION, TEST_PROJECT, TEST_PUBLISHER_MODEL_ENDPOINT, TEST_TOKEN_PROMISE, req, TEST_API_ENDPOINT);
        expect(resp).toEqual(expectedResult);
    });
    it('returns a GenerateContentResponse when passed a string', async () => {
        const expectedResult = {
            response: TEST_MODEL_RESPONSE,
        };
        spyOn(StreamFunctions, 'processNonStream').and.resolveTo(expectedResult);
        const resp = await (0, generate_content_1.generateContent)(TEST_LOCATION, TEST_PROJECT, TEST_PUBLISHER_MODEL_ENDPOINT, TEST_TOKEN_PROMISE, TEST_CHAT_MESSAGE_TEXT, TEST_API_ENDPOINT);
        expect(resp).toEqual(expectedResult);
    });
    it('returns a GenerateContentResponse when passed a GCS URI', async () => {
        const req = {
            contents: TEST_USER_CHAT_MESSAGE_WITH_GCS_FILE,
        };
        const expectedResult = {
            response: TEST_MODEL_RESPONSE,
        };
        spyOn(StreamFunctions, 'processNonStream').and.resolveTo(expectedResult);
        const resp = await (0, generate_content_1.generateContent)(TEST_LOCATION, TEST_PROJECT, TEST_PUBLISHER_MODEL_ENDPOINT, TEST_TOKEN_PROMISE, req, TEST_API_ENDPOINT);
        expect(resp).toEqual(expectedResult);
    });
    it('raises an error when passed an invalid GCS URI', async () => {
        const req = {
            contents: TEST_USER_CHAT_MESSAGE_WITH_INVALID_GCS_FILE,
        };
        await expectAsync((0, generate_content_1.generateContent)(TEST_LOCATION, TEST_PROJECT, TEST_PUBLISHER_MODEL_ENDPOINT, TEST_TOKEN_PROMISE, req, TEST_API_ENDPOINT)).toBeRejectedWithError(URIError);
    });
    it('returns a GenerateContentResponse when passed safety_settings and generation_config', async () => {
        const req = {
            contents: TEST_USER_CHAT_MESSAGE,
            safety_settings: TEST_SAFETY_SETTINGS,
            generation_config: TEST_GENERATION_CONFIG,
        };
        const expectedResult = {
            response: TEST_MODEL_RESPONSE,
        };
        spyOn(StreamFunctions, 'processNonStream').and.resolveTo(expectedResult);
        const resp = await (0, generate_content_1.generateContent)(TEST_LOCATION, TEST_PROJECT, TEST_PUBLISHER_MODEL_ENDPOINT, TEST_TOKEN_PROMISE, req, TEST_API_ENDPOINT);
        expect(resp).toEqual(expectedResult);
    });
    it('updates the base API endpoint when provided', async () => {
        const req = {
            contents: TEST_USER_CHAT_MESSAGE,
        };
        const expectedResult = {
            response: TEST_MODEL_RESPONSE,
        };
        spyOn(StreamFunctions, 'processNonStream').and.resolveTo(expectedResult);
        await (0, generate_content_1.generateContent)(TEST_LOCATION, TEST_PROJECT, TEST_PUBLISHER_MODEL_ENDPOINT, TEST_TOKEN_PROMISE, req, TEST_ENDPOINT_BASE_PATH);
        expect(fetchSpy.calls.allArgs()[0][0].toString()).toContain(TEST_ENDPOINT_BASE_PATH);
    });
    it('removes top_k when it is set to 0', async () => {
        const reqWithEmptyConfigs = {
            contents: TEST_USER_CHAT_MESSAGE_WITH_GCS_FILE,
            generation_config: { top_k: 0 },
            safety_settings: [],
        };
        const expectedResult = {
            response: TEST_MODEL_RESPONSE,
        };
        spyOn(StreamFunctions, 'processNonStream').and.resolveTo(expectedResult);
        await (0, generate_content_1.generateContent)(TEST_LOCATION, TEST_PROJECT, TEST_PUBLISHER_MODEL_ENDPOINT, TEST_TOKEN_PROMISE, reqWithEmptyConfigs, TEST_API_ENDPOINT);
        const requestArgs = fetchSpy.calls.allArgs()[0][1];
        if (typeof requestArgs === 'object' && requestArgs) {
            expect(JSON.stringify(requestArgs['body'])).not.toContain('top_k');
        }
    });
    it('includes top_k when it is within 1 - 40', async () => {
        const reqWithEmptyConfigs = {
            contents: TEST_USER_CHAT_MESSAGE_WITH_GCS_FILE,
            generation_config: { top_k: 1 },
            safety_settings: [],
        };
        const expectedResult = {
            response: TEST_MODEL_RESPONSE,
        };
        spyOn(StreamFunctions, 'processNonStream').and.resolveTo(expectedResult);
        await (0, generate_content_1.generateContent)(TEST_LOCATION, TEST_PROJECT, TEST_PUBLISHER_MODEL_ENDPOINT, TEST_TOKEN_PROMISE, reqWithEmptyConfigs, TEST_API_ENDPOINT);
        const requestArgs = fetchSpy.calls.allArgs()[0][1];
        if (typeof requestArgs === 'object' && requestArgs) {
            expect(JSON.stringify(requestArgs['body'])).toContain('top_k');
        }
    });
    it('aggregates citation metadata', async () => {
        var _a;
        const req = {
            contents: TEST_USER_CHAT_MESSAGE,
        };
        const expectedResult = {
            response: TEST_MODEL_RESPONSE,
        };
        spyOn(StreamFunctions, 'processNonStream').and.resolveTo(expectedResult);
        const resp = await (0, generate_content_1.generateContent)(TEST_LOCATION, TEST_PROJECT, TEST_PUBLISHER_MODEL_ENDPOINT, TEST_TOKEN_PROMISE, req, TEST_API_ENDPOINT);
        expect((_a = resp.response.candidates[0].citationMetadata) === null || _a === void 0 ? void 0 : _a.citationSources.length).toEqual(TEST_MODEL_RESPONSE.candidates[0].citationMetadata.citationSources.length);
    });
    it('returns a FunctionCall when passed a FunctionDeclaration', async () => {
        const req = {
            contents: [
                { role: 'user', parts: [{ text: 'What is the weater like in Boston?' }] },
            ],
            tools: TEST_TOOLS_WITH_FUNCTION_DECLARATION,
        };
        const expectedResult = {
            response: TEST_MODEL_RESPONSE_WITH_FUNCTION_CALL,
        };
        spyOn(StreamFunctions, 'processNonStream').and.resolveTo(expectedResult);
        const resp = await (0, generate_content_1.generateContent)(TEST_LOCATION, TEST_PROJECT, TEST_PUBLISHER_MODEL_ENDPOINT, TEST_TOKEN_PROMISE, req, TEST_API_ENDPOINT);
        expect(resp).toEqual(expectedResult);
    });
    it('throws ClientError when functionResponse is not immedidately following functionCall case1', async () => {
        const req = {
            contents: [
                {
                    role: 'user',
                    parts: [{ text: 'What is the weater like in Boston?' }],
                },
                {
                    role: 'function',
                    parts: TEST_FUNCTION_RESPONSE_PART,
                },
            ],
            tools: TEST_TOOLS_WITH_FUNCTION_DECLARATION,
        };
        const expectedErrorMessage = '[VertexAI.ClientError]: Please ensure that function response turn comes immediately after a function call turn.';
        await (0, generate_content_1.generateContent)(TEST_LOCATION, TEST_PROJECT, TEST_PUBLISHER_MODEL_ENDPOINT, TEST_TOKEN_PROMISE, req, TEST_API_ENDPOINT).catch(e => {
            expect(e.message).toEqual(expectedErrorMessage);
        });
    });
    it('throws ClientError when functionResponse is not immedidately following functionCall case2', async () => {
        const req = {
            contents: [
                {
                    role: 'user',
                    parts: [{ text: 'What is the weater like in Boston?' }],
                },
                {
                    role: 'function',
                    parts: TEST_FUNCTION_RESPONSE_PART,
                },
            ],
            tools: TEST_TOOLS_WITH_FUNCTION_DECLARATION,
        };
        const expectedErrorMessage = '[VertexAI.ClientError]: Please ensure that function response turn comes immediately after a function call turn.';
        await (0, generate_content_1.generateContent)(TEST_LOCATION, TEST_PROJECT, TEST_PUBLISHER_MODEL_ENDPOINT, TEST_TOKEN_PROMISE, req, TEST_API_ENDPOINT).catch(e => {
            expect(e.message).toEqual(expectedErrorMessage);
        });
    });
});
describe('generateContentStream', () => {
    let expectedStreamResult;
    let fetchSpy;
    beforeEach(() => {
        expectedStreamResult = {
            response: Promise.resolve(TEST_MODEL_RESPONSE),
            stream: testGenerator(),
        };
        const fetchResult = new Response(JSON.stringify(expectedStreamResult), fetchResponseObj);
        fetchSpy = spyOn(global, 'fetch').and.resolveTo(fetchResult);
    });
    it('returns a GenerateContentResponse when passed text content', async () => {
        const req = {
            contents: TEST_USER_CHAT_MESSAGE,
        };
        const expectedResult = {
            response: Promise.resolve(TEST_MODEL_RESPONSE),
            stream: testGenerator(),
        };
        spyOn(StreamFunctions, 'processStream').and.resolveTo(expectedResult);
        const resp = await (0, generate_content_1.generateContentStream)(TEST_LOCATION, TEST_PROJECT, TEST_PUBLISHER_MODEL_ENDPOINT, TEST_TOKEN_PROMISE, req, TEST_API_ENDPOINT);
        expect(resp).toEqual(expectedResult);
    });
    it('returns a GenerateContentResponse when passed a string', async () => {
        const expectedResult = {
            response: Promise.resolve(TEST_MODEL_RESPONSE),
            stream: testGenerator(),
        };
        spyOn(StreamFunctions, 'processStream').and.resolveTo(expectedResult);
        const resp = await (0, generate_content_1.generateContentStream)(TEST_LOCATION, TEST_PROJECT, TEST_PUBLISHER_MODEL_ENDPOINT, TEST_TOKEN_PROMISE, TEST_API_ENDPOINT, TEST_CHAT_MESSAGE_TEXT);
        expect(resp).toEqual(expectedResult);
    });
    it('returns a GenerateContentResponse when passed multi-part content with a GCS URI', async () => {
        const req = {
            contents: TEST_MULTIPART_MESSAGE,
        };
        const expectedResult = {
            response: Promise.resolve(TEST_MODEL_RESPONSE),
            stream: testGenerator(),
        };
        spyOn(StreamFunctions, 'processStream').and.resolveTo(expectedResult);
        const resp = await (0, generate_content_1.generateContentStream)(TEST_LOCATION, TEST_PROJECT, TEST_PUBLISHER_MODEL_ENDPOINT, TEST_TOKEN_PROMISE, req, TEST_API_ENDPOINT);
        expect(resp).toEqual(expectedResult);
    });
    it('returns a GenerateContentResponse when passed multi-part content with base64 data', async () => {
        const req = {
            contents: TEST_MULTIPART_MESSAGE_BASE64,
        };
        const expectedResult = {
            response: Promise.resolve(TEST_MODEL_RESPONSE),
            stream: testGenerator(),
        };
        spyOn(StreamFunctions, 'processStream').and.resolveTo(expectedResult);
        const resp = await (0, generate_content_1.generateContentStream)(TEST_LOCATION, TEST_PROJECT, TEST_PUBLISHER_MODEL_ENDPOINT, TEST_TOKEN_PROMISE, req, TEST_API_ENDPOINT);
        expect(resp).toEqual(expectedResult);
    });
    it('returns a FunctionCall when passed a FunctionDeclaration', async () => {
        const req = {
            contents: [
                { role: 'user', parts: [{ text: 'What is the weater like in Boston?' }] },
            ],
            tools: TEST_TOOLS_WITH_FUNCTION_DECLARATION,
        };
        const expectedStreamResult = {
            response: Promise.resolve(TEST_MODEL_RESPONSE_WITH_FUNCTION_CALL),
            stream: testGenerator(),
        };
        spyOn(StreamFunctions, 'processStream').and.resolveTo(expectedStreamResult);
        const resp = await (0, generate_content_1.generateContentStream)(TEST_LOCATION, TEST_PROJECT, TEST_PUBLISHER_MODEL_ENDPOINT, TEST_TOKEN_PROMISE, req, TEST_API_ENDPOINT);
        expect(resp).toEqual(expectedStreamResult);
    });
    it('throws ClientError when functionResponse is not immedidately following functionCall case1', async () => {
        const req = {
            contents: [
                {
                    role: 'user',
                    parts: [{ text: 'What is the weater like in Boston?' }],
                },
                {
                    role: 'function',
                    parts: TEST_FUNCTION_RESPONSE_PART,
                },
            ],
            tools: TEST_TOOLS_WITH_FUNCTION_DECLARATION,
        };
        const expectedErrorMessage = '[VertexAI.ClientError]: Please ensure that function response turn comes immediately after a function call turn.';
        await (0, generate_content_1.generateContentStream)(TEST_LOCATION, TEST_PROJECT, TEST_PUBLISHER_MODEL_ENDPOINT, TEST_TOKEN_PROMISE, req, TEST_API_ENDPOINT).catch(e => {
            expect(e.message).toEqual(expectedErrorMessage);
        });
    });
    it('throws ClientError when functionResponse is not immedidately following functionCall case2', async () => {
        const req = {
            contents: [
                {
                    role: 'user',
                    parts: [{ text: 'What is the weater like in Boston?' }],
                },
                {
                    role: 'function',
                    parts: TEST_FUNCTION_RESPONSE_PART,
                },
            ],
            tools: TEST_TOOLS_WITH_FUNCTION_DECLARATION,
        };
        const expectedErrorMessage = '[VertexAI.ClientError]: Please ensure that function response turn comes immediately after a function call turn.';
        await (0, generate_content_1.generateContentStream)(TEST_LOCATION, TEST_PROJECT, TEST_PUBLISHER_MODEL_ENDPOINT, TEST_TOKEN_PROMISE, req, TEST_API_ENDPOINT).catch(e => {
            expect(e.message).toEqual(expectedErrorMessage);
        });
    });
});
//# sourceMappingURL=functions_test.js.map