"use strict";
/**
 * @license
 * Copyright 2023 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
Object.defineProperty(exports, "__esModule", { value: true });
exports.FunctionDeclarationSchemaType = exports.FinishReason = exports.BlockedReason = exports.HarmProbability = exports.HarmBlockThreshold = exports.HarmCategory = void 0;
/**
 * @enum {string}
 * Harm categories that will block the content.
 * Values:
 *     HARM_CATEGORY_UNSPECIFIED:
 *         The harm category is unspecified.
 *     HARM_CATEGORY_HATE_SPEECH:
 *         The harm category is hate speech.
 *     HARM_CATEGORY_DANGEROUS_CONTENT:
 *         The harm category is dangerous content.
 *     HARM_CATEGORY_HARASSMENT:
 *         The harm category is harassment.
 *     HARM_CATEGORY_SEXUALLY_EXPLICIT:
 *         The harm category is sexually explicit
 *         content.
 */
var HarmCategory;
(function (HarmCategory) {
    HarmCategory["HARM_CATEGORY_UNSPECIFIED"] = "HARM_CATEGORY_UNSPECIFIED";
    HarmCategory["HARM_CATEGORY_HATE_SPEECH"] = "HARM_CATEGORY_HATE_SPEECH";
    HarmCategory["HARM_CATEGORY_DANGEROUS_CONTENT"] = "HARM_CATEGORY_DANGEROUS_CONTENT";
    HarmCategory["HARM_CATEGORY_HARASSMENT"] = "HARM_CATEGORY_HARASSMENT";
    HarmCategory["HARM_CATEGORY_SEXUALLY_EXPLICIT"] = "HARM_CATEGORY_SEXUALLY_EXPLICIT";
})(HarmCategory || (exports.HarmCategory = HarmCategory = {}));
/**
 * @enum {string}
 * Probability based thresholds levels for blocking.
 * Values:
 *      HARM_BLOCK_THRESHOLD_UNSPECIFIED:
 *          Unspecified harm block threshold.
 *      BLOCK_LOW_AND_ABOVE:
 *          Block low threshold and above (i.e. block
 *          more).
 *      BLOCK_MEDIUM_AND_ABOVE:
 *          Block medium threshold and above.
 *      BLOCK_ONLY_HIGH:
 *          Block only high threshold (i.e. block less).
 *      BLOCK_NONE:
 *          Block none.
 */
var HarmBlockThreshold;
(function (HarmBlockThreshold) {
    HarmBlockThreshold["HARM_BLOCK_THRESHOLD_UNSPECIFIED"] = "HARM_BLOCK_THRESHOLD_UNSPECIFIED";
    HarmBlockThreshold["BLOCK_LOW_AND_ABOVE"] = "BLOCK_LOW_AND_ABOVE";
    HarmBlockThreshold["BLOCK_MEDIUM_AND_ABOVE"] = "BLOCK_MEDIUM_AND_ABOVE";
    HarmBlockThreshold["BLOCK_ONLY_HIGH"] = "BLOCK_ONLY_HIGH";
    HarmBlockThreshold["BLOCK_NONE"] = "BLOCK_NONE";
})(HarmBlockThreshold || (exports.HarmBlockThreshold = HarmBlockThreshold = {}));
/**
 * @enum {string}
 * Harm probability levels in the content.
 * Values:
 *     HARM_PROBABILITY_UNSPECIFIED:
 *         Harm probability unspecified.
 *     NEGLIGIBLE:
 *         Negligible level of harm.
 *     LOW:
 *         Low level of harm.
 *     MEDIUM:
 *         Medium level of harm.
 *     HIGH:
 *         High level of harm.
 */
var HarmProbability;
(function (HarmProbability) {
    HarmProbability["HARM_PROBABILITY_UNSPECIFIED"] = "HARM_PROBABILITY_UNSPECIFIED";
    HarmProbability["NEGLIGIBLE"] = "NEGLIGIBLE";
    HarmProbability["LOW"] = "LOW";
    HarmProbability["MEDIUM"] = "MEDIUM";
    HarmProbability["HIGH"] = "HIGH";
})(HarmProbability || (exports.HarmProbability = HarmProbability = {}));
/**
 * @enum {string}
 * The reason why the reponse is blocked.
 * Values:
 *   BLOCKED_REASON_UNSPECIFIED
 *       Unspecified blocked reason.
 *   SAFETY
 *       Candidates blocked due to safety.
 *   OTHER
 *       Candidates blocked due to other reason.
 */
var BlockedReason;
(function (BlockedReason) {
    BlockedReason["BLOCKED_REASON_UNSPECIFIED"] = "BLOCK_REASON_UNSPECIFIED";
    BlockedReason["SAFETY"] = "SAFETY";
    BlockedReason["OTHER"] = "OTHER";
})(BlockedReason || (exports.BlockedReason = BlockedReason = {}));
/**
 * @enum {string}
 * The reason why the model stopped generating tokens.
 * If empty, the model has not stopped generating the tokens.
 * Values:
 *   FINISH_REASON_UNSPECIFIED
 *       The finish reason is unspecified.
 *   STOP:
 *       Natural stop point of the model or provided
 *       stop sequence.
 *   MAX_TOKENS:
 *       The maximum number of tokens as specified in
 *       the request was reached.
 *   SAFETY:
 *       The token generation was stopped as the
 *       response was flagged for safety reasons. NOTE:
 *       When streaming the Candidate.content will be
 *       empty if content filters blocked the output.
 *   RECITATION:
 *       The token generation was stopped as the
 *       response was flagged for unauthorized citations.
 *   OTHER:
 *       All other reasons that stopped the token
 *       generation
 */
var FinishReason;
(function (FinishReason) {
    FinishReason["FINISH_REASON_UNSPECIFIED"] = "FINISH_REASON_UNSPECIFIED";
    FinishReason["STOP"] = "STOP";
    FinishReason["MAX_TOKENS"] = "MAX_TOKENS";
    FinishReason["SAFETY"] = "SAFETY";
    FinishReason["RECITATION"] = "RECITATION";
    FinishReason["OTHER"] = "OTHER";
})(FinishReason || (exports.FinishReason = FinishReason = {}));
/**
 * Contains the list of OpenAPI data types
 * as defined by https://swagger.io/docs/specification/data-models/data-types/
 * @public
 */
var FunctionDeclarationSchemaType;
(function (FunctionDeclarationSchemaType) {
    FunctionDeclarationSchemaType["STRING"] = "STRING";
    FunctionDeclarationSchemaType["NUMBER"] = "NUMBER";
    FunctionDeclarationSchemaType["INTEGER"] = "INTEGER";
    FunctionDeclarationSchemaType["BOOLEAN"] = "BOOLEAN";
    FunctionDeclarationSchemaType["ARRAY"] = "ARRAY";
    FunctionDeclarationSchemaType["OBJECT"] = "OBJECT";
})(FunctionDeclarationSchemaType || (exports.FunctionDeclarationSchemaType = FunctionDeclarationSchemaType = {}));
//# sourceMappingURL=content.js.map